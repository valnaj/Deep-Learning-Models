{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "cuDNN is available\n",
      "Device is set to: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# see if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "\n",
    "# see if cuDNN is available\n",
    "if torch.backends.cudnn.enabled:\n",
    "    print(\"cuDNN is available\")\n",
    "\n",
    "# set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is set to:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torchmetrics\n",
    "import tensorboard\n",
    "\n",
    "class CIFAR100DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir='./data', batch_size=128):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Load data\n",
    "        cifar100_train = datasets.CIFAR100(root=self.data_dir, train=True, download=True, transform=self.transform)\n",
    "        cifar100_test = datasets.CIFAR100(root=self.data_dir, train=False, download=True, transform=self.transform)\n",
    "\n",
    "        # Train/val split\n",
    "        self.train, self.val = random_split(cifar100_train, [45000, 5000])\n",
    "        self.test = cifar100_test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, num_workers=7, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size, num_workers=7, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, num_workers=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, c1, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, c2[0], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, c3[0], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, c4, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([\n",
    "            self.b1(x),\n",
    "            self.b2(x),\n",
    "            self.b3(x),\n",
    "            self.b4(x)\n",
    "        ], dim=1)\n",
    "\n",
    "class GoogLeNet(pl.LightningModule):\n",
    "    def __init__(self, num_classes=100, learning_rate=0.01):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.inception3a = InceptionModule(192, 64, (96, 128), (16, 32), 32)\n",
    "        self.inception3b = InceptionModule(256, 128, (128, 192), (32, 96), 64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception4a = InceptionModule(480, 192, (96, 208), (16, 48), 64)\n",
    "        self.inception4b = InceptionModule(512, 160, (112, 224), (24, 64), 64)\n",
    "        self.inception4c = InceptionModule(512, 128, (128, 256), (24, 64), 64)\n",
    "        self.inception4d = InceptionModule(512, 112, (144, 288), (32, 64), 64)\n",
    "        self.inception4e = InceptionModule(528, 256, (160, 320), (32, 128), 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception5a = InceptionModule(832, 256, (160, 320), (32, 128), 128)\n",
    "        self.inception5b = InceptionModule(832, 384, (192, 384), (48, 128), 128)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        # accuracy:\n",
    "        self.train_acc = torchmetrics.Accuracy(num_classes=num_classes, average='macro', task='multiclass')\n",
    "        self.val_acc = torchmetrics.Accuracy(num_classes=num_classes, average='macro', task='multiclass')\n",
    "\n",
    "        # testing metrics:\n",
    "        self.test_acc = torchmetrics.Accuracy(num_classes=num_classes, average='macro', task='multiclass')\n",
    "        self.test_precision = torchmetrics.Precision(num_classes=num_classes, average='macro', task='multiclass')\n",
    "        self.test_recall = torchmetrics.Recall(num_classes=num_classes, average='macro', task='multiclass')\n",
    "        self.test_f1 = torchmetrics.F1Score(num_classes=num_classes, average='macro', task='multiclass')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.train_acc(logits, y)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', self.train_acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.val_acc(logits, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        # Update metrics\n",
    "        acc = self.test_acc(logits, y)\n",
    "        precision = self.test_precision(logits, y)\n",
    "        recall = self.test_recall(logits, y)\n",
    "        f1 = self.test_f1(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_epoch=True)\n",
    "        self.log('test_precision', precision, on_epoch=True)\n",
    "        self.log('test_recall', recall, on_epoch=True)\n",
    "        self.log('test_f1', f1, on_epoch=True)\n",
    "        return {\"loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type                | Params\n",
      "--------------------------------------------------------\n",
      "0  | stem           | Sequential          | 124 K \n",
      "1  | inception3a    | InceptionModule     | 163 K \n",
      "2  | inception3b    | InceptionModule     | 388 K \n",
      "3  | maxpool        | MaxPool2d           | 0     \n",
      "4  | inception4a    | InceptionModule     | 376 K \n",
      "5  | inception4b    | InceptionModule     | 449 K \n",
      "6  | inception4c    | InceptionModule     | 510 K \n",
      "7  | inception4d    | InceptionModule     | 605 K \n",
      "8  | inception4e    | InceptionModule     | 868 K \n",
      "9  | maxpool2       | MaxPool2d           | 0     \n",
      "10 | inception5a    | InceptionModule     | 1.0 M \n",
      "11 | inception5b    | InceptionModule     | 1.4 M \n",
      "12 | avgpool        | AdaptiveAvgPool2d   | 0     \n",
      "13 | flatten        | Flatten             | 0     \n",
      "14 | fc             | Linear              | 102 K \n",
      "15 | train_acc      | MulticlassAccuracy  | 0     \n",
      "16 | val_acc        | MulticlassAccuracy  | 0     \n",
      "17 | test_acc       | MulticlassAccuracy  | 0     \n",
      "18 | test_precision | MulticlassPrecision | 0     \n",
      "19 | test_recall    | MulticlassRecall    | 0     \n",
      "20 | test_f1        | MulticlassF1Score   | 0     \n",
      "--------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.304    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 3/352 [00:00<00:58,  6.00it/s, v_num=59, train_loss_step=4.600, train_acc_step=0.0135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Documents\\MMA\\MULTI TASK\\Final Project\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 352/352 [00:08<00:00, 40.40it/s, v_num=59, train_loss_step=4.140, train_acc_step=0.0492, val_loss=4.210, val_acc=0.0301, train_loss_epoch=4.360, train_acc_epoch=0.0248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 352/352 [00:08<00:00, 43.62it/s, v_num=59, train_loss_step=4.100, train_acc_step=0.00505, val_loss=4.100, val_acc=0.0557, train_loss_epoch=4.120, train_acc_epoch=0.0417]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.115 >= min_delta = 0.0. New best score: 4.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 352/352 [00:08<00:00, 43.60it/s, v_num=59, train_loss_step=3.820, train_acc_step=0.0702, val_loss=3.910, val_acc=0.0601, train_loss_epoch=3.960, train_acc_epoch=0.0634] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.187 >= min_delta = 0.0. New best score: 3.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 352/352 [00:08<00:00, 43.96it/s, v_num=59, train_loss_step=3.750, train_acc_step=0.0833, val_loss=3.770, val_acc=0.0893, train_loss_epoch=3.810, train_acc_epoch=0.0839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.142 >= min_delta = 0.0. New best score: 3.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 352/352 [00:08<00:00, 41.20it/s, v_num=59, train_loss_step=3.500, train_acc_step=0.0923, val_loss=3.560, val_acc=0.132, train_loss_epoch=3.570, train_acc_epoch=0.119]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.206 >= min_delta = 0.0. New best score: 3.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 352/352 [00:08<00:00, 43.20it/s, v_num=59, train_loss_step=3.230, train_acc_step=0.0931, val_loss=3.430, val_acc=0.165, train_loss_epoch=3.380, train_acc_epoch=0.158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.130 >= min_delta = 0.0. New best score: 3.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 352/352 [00:07<00:00, 44.11it/s, v_num=59, train_loss_step=3.210, train_acc_step=0.171, val_loss=3.300, val_acc=0.179, train_loss_epoch=3.230, train_acc_epoch=0.188] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.129 >= min_delta = 0.0. New best score: 3.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 352/352 [00:07<00:00, 44.12it/s, v_num=59, train_loss_step=3.060, train_acc_step=0.192, val_loss=3.250, val_acc=0.207, train_loss_epoch=3.090, train_acc_epoch=0.214] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.057 >= min_delta = 0.0. New best score: 3.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 352/352 [00:08<00:00, 43.06it/s, v_num=59, train_loss_step=3.080, train_acc_step=0.149, val_loss=3.210, val_acc=0.205, train_loss_epoch=2.960, train_acc_epoch=0.244] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.034 >= min_delta = 0.0. New best score: 3.214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 352/352 [00:08<00:00, 43.27it/s, v_num=59, train_loss_step=2.780, train_acc_step=0.176, val_loss=3.160, val_acc=0.222, train_loss_epoch=2.840, train_acc_epoch=0.266]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.057 >= min_delta = 0.0. New best score: 3.157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 352/352 [00:08<00:00, 43.62it/s, v_num=59, train_loss_step=2.670, train_acc_step=0.211, val_loss=3.110, val_acc=0.243, train_loss_epoch=2.740, train_acc_epoch=0.287]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.047 >= min_delta = 0.0. New best score: 3.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 352/352 [00:08<00:00, 43.50it/s, v_num=59, train_loss_step=2.930, train_acc_step=0.219, val_loss=3.100, val_acc=0.248, train_loss_epoch=2.630, train_acc_epoch=0.307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 3.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 352/352 [00:08<00:00, 43.75it/s, v_num=59, train_loss_step=1.660, train_acc_step=0.404, val_loss=3.510, val_acc=0.260, train_loss_epoch=1.780, train_acc_epoch=0.498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 3.099. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 352/352 [00:09<00:00, 38.40it/s, v_num=59, train_loss_step=1.660, train_acc_step=0.404, val_loss=3.510, val_acc=0.260, train_loss_epoch=1.780, train_acc_epoch=0.498]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Owner\\Documents\\MMA\\MULTI TASK\\Final Project\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:01<00:00, 57.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22750820219516754    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2082616239786148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.380080461502075     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22547651827335358    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22750820219516754    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22750820219516754   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2082616239786148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.380080461502075    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22547651827335358   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22750820219516754   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 3.380080461502075,\n",
       "  'test_acc': 0.22750820219516754,\n",
       "  'test_precision': 0.22547651827335358,\n",
       "  'test_recall': 0.22750820219516754,\n",
       "  'test_f1': 0.2082616239786148}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.00,\n",
    "    patience =  10,\n",
    "    verbose = True,\n",
    "    mode = 'min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='max', \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "data_module = CIFAR100DataModule()\n",
    "model = GoogLeNet(num_classes=100, learning_rate=0.001)\n",
    "logger = TensorBoardLogger('C:/Users/Owner/Documents/MMA/MULTI TASK/Final Project/', name='cnn_logs')\n",
    "trainer = pl.Trainer(max_epochs=500, devices=1 if torch.cuda.is_available() else 0, callbacks=[early_stopping, checkpoint_callback])\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
